x + y
class(x+y)
read.csv(hw1_data.csv)
read.csv("hw1_data.csv")
data = read.csv("hw1_data.csv")
data[1]
data[[1]]
data[header]
header[data]
str(data)
data[1:2,]
data[153,]
data[154,]
data[152:153,]
data[47,Ozone]
data[47,"Ozone"]
data[47,]
data[,"Ozone"]
is.na(data[,"Ozone"])
is.na(data[,"Ozone"]) == F
table(is.na(data[,"Ozone"])
)
mean(data[,"Ozone"])
mean(data[,"Ozone"], na.rm = T)
data[,"Ozone"] > 31
x = data[,"Ozone"] > 31
data[x]
data[x, ]
data[x, "Ozone"]
data
data[,"Ozone" == 41]
data[,"Ozone"]
data$Ozone
data$Ozone =>41
data[data$Ozone == 41]
data[,Ozone[]]
subset(data, Ozone = 41)
subset(data, Ozone == 41)
subset(data, Ozone > 31 && Temp > 90)
subset(data, Temp > 90)
subset(data, Ozone > 31 & Temp > 90)
x = subset(data, Ozone > 31 & Temp > 90)
x
mean(x[,Solar.R])
mean(x[,"Solar.R])
""
)
]
"])
mean(x[,"Solar.R"])
x = subset(data, Month == 6)
x
mean(x[,"Temp"])
x = subset(data, Month == 5)
x
max(x[,"Ozone"])
x[,"Ozone"]
x[,"Ozone",na.rm=T]
max(x[,"Ozone"], na.rm = T)
above <- function(x, y = 10) {
use <- x > y
x[use]
}
above(1:50)
add <- function(test1, app) {
test1 + app
}
add(app=1, tes=2)
add(app=1, 2)
add <- function(test1, app) {
print(test1)
print(app)
}
add(app=1, 2)
add(app=1, tes=2)
cube <- function(x, n) { x^3 }
cube(3)
x <- 1:10
if(x > 5) {
x <- 0}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
system.time()
system.time(letters)
set.seed(1)
rpois(5, 2)
set.seed(1)
rpois(5, 2)
rep(0:1, each = 5)
library(swirl)
swirl()
head(flags)
dim(flags)
play()
str(flags)
names(flags)
flags$name
flags["name",]
flags[."name"]
flags[,"name"]
nxt()
class(flagts)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
cbind(flags$name, as.character(cls_list))
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
sapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags,
unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
Use table(flags$animate)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 19)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
flips <- sample(c(0,1), 100, replace=TRUE, prob = c(0.3, 0.7) )
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(10, mean = 100, sd = 25)
rpois(5, 10)
replicate(100, rpois(5, 10))
my_pois <- replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass()
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
t2
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x=cars$speed, y=cars$dist)
plot(y=cars$speed, x=cars$dist)
plot(x=cars$speed, y=cars$dist, xlab = "Speed")
plot(x=cars$speed, y=cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x=cars$speed, y=cars$dist, ylab = "Stopping Distance")
plot(x=cars$speed, y=cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(cars, main="My Plot")
plot(cars, sub="My Plot Subtitle")
plot(cars, col=2)
plot(cars, slim=c(10,15))
plot(cars, xlim = c(10, 15))
plot(cars, pch=2)
data(mtcars)
?boxplot
boxplot(formula = mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
exit
quit()
source('~/datasciencecoursera/R programming/cachematrix.R')
x = rbind(c(1, -1/4), c(-1/4, 1))
m = makeCacheMatrix(x)
m$get()
> cacheSolve(m)
cacheSolve(m)
cacheSolve(m)
source('~/datasciencecoursera/R programming/cachematrix.R')
library(xlsx)
library(rJava)
library(rJava)
library(rJava)
Sys.getenv("JAVA_HOME")
install.packages("xlsxjars")
library(xlsx)
library(rJava)
~/.Rprofile
file.edit('~/.Rprofile')
install_package("pander")
install.package("pander")
install.packages("pander")
nsim <- 1000
nvals <- 40
lambda <- 0.2
set.seed(567)
simdata <- t(replicate(nsim, rexp(nvals, lambda)))
df <- data.frame(Mean=c(mean(rowMeans(simdata)), 1/lambda),
Variance=c(mean(apply(simdata, 1, var)), 1/lambda^2))
rownames(df) <- c("Simulated", "Theoretical")
#pander(df, round=2)
hist(df)
View(df)
hist(df$Variance)
hist(df$Mean)
hist(df$Variance)
library(qplot)
install.packages("qplot")
library(ggplot2)
library(ggplot)
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
find(qplot)
find("qplot")
library(swirl)
ls()
rm(list=ls())
swirl()
exit
exit()
q
install_from_swirl("Statistical Inference")
install.packages("swirl")
library(swirl)
install_from_swirl("Statistical Inference")
rm(list=ls())
install_from_swirl("Statistical Inference")
install_from_swirl("Statistical Inference")
install.packages("swirl")
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
33/36
deck
52
4/52
0
12/52
3/51
2/50
2/51
1.28
0.64
1.36
0.64
mypdf
integrate(mypdf,0,1.6)
1.414214
.997*.001
(1-.985)*(1-.001)
.000997/(.000997+.014985)
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
3.5
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam,1,mean)
mean(smeans)
bye
bye()
bye()
exit()
library(swirl)
swirl()
install_from_swirl("Regression Models")
install_from_swirl("Regression Models")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
library(swirl)
ls()
rm(list=ls())
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rhs
all.equal(lhs,rhs)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
fit <- lm(child ~ parent, galton)
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$parent,galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ . - 1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ . - 1, trees2)
lapply(list(fit, fit2), coef)
swirl()
library(swirl)
rm(list=ls())
attach(mtcars)
head(mtcars,5)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
library(elasticnet)
install_package(ElemStatLearn)
install.packages(ElemStatLearn)
install.packages("ElemStatLearn"")
z
;
""
install.packages("ElemStatLearn)
""
''
z"
"
""
"
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
library(elasticnet)
install.packages("caret")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages("gbm")
install.packages("mgcv")
install.packages("mgcv")
install.packages("mgcv")
install.packages("mgcv")
install.packages("nlme")
install.packages("elasticnet")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
library(gbm)
library(mgcv)
library(nlme)
library(elasticnet)
prf <- predict(rf, vowel.test)
pgbm <- predict(gbm, vowel.test)
cmrf <- confusionMatrix(prf, vowel.test$y)
cmgbm <- confusionMatrix(pgbm, vowel.test$y)
cmrf$overall['Accuracy']
setwd("~/datasciencecoursera/Practical Machine Learning/project")
setwd("~/datasciencecoursera/Practical Machine Learning/project")
# Remove everything in current working library
# rm(list = ls())
# Read cleaned training and testing data
training <- read.table(file = "./data/pml-training2.csv", header = TRUE, sep = ",", quote = "")
testing <- read.table(file = "./data/pml-testing2.csv", header = TRUE, sep = ",", quote = "")
# Change the numeric type to integer type to make sure
# the same data type in training data and testing data
training$magnet_dumbbell_z <- as.integer(training$magnet_dumbbell_z)
training$magnet_forearm_y <- as.integer(training$magnet_forearm_y)
training$magnet_forearm_z <- as.integer(training$magnet_forearm_z)
levels(testing$new_window) <- levels(training$new_window)
Install randomForest package
install.packages("randomForest")
install.packages("caret")
library(randomForest)
library(caret)
set.seed(111)
fitControl = trainControl( method = "cv", number = 2)
cv <- train(classe ~ ., data = training, method = "rf",
trControl = fitControl)
cv$bestTune$mtry
cv <- train(classe ~ ., data = training, method = "rf", trControl = fitControl)
install.packages('e1071', dependencies=TRUE)
cv <- train(classe ~ ., data = training, method = "rf", trControl = fitControl)
cv$bestTune$mtry
cv
RandomForest = randomForest(classe ~ ., data = training, mtry = cv$bestTune$mtry)
PredictForTrain = predict(RandomForest)
table(PredictForTrain, training$classe)
PredictForest = predict(RandomForest, newdata = testing)
PredictForest
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_", i ,".txt")
write.table(x[i], file = filename, quote = FALSE,
row.names = FALSE, col.names = FALSE)
}
}
pml_write_files(PredictForest)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("./submission/problem_id_", i ,".txt")
write.table(x[i], file = filename, quote = FALSE,
row.names = FALSE, col.names = FALSE)
}
}
pml_write_files(PredictForest)
